{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedanshipathak/Mental-Health-Support-Chatbot/blob/main/Final_Model_mental_health_support.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPDV75AcUIjO"
      },
      "outputs": [],
      "source": [
        "!pip install langchain chromadb openai flask datasets evaluate torch transformers accelerate faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5I4toAtUtlT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv(r'/content/counselchat-data.csv')\n",
        "\n",
        "# Function to strip HTML tags (like <p>, <br>, etc.)\n",
        "def remove_html_tags(text):\n",
        "    clean = re.compile('<.*?>')\n",
        "    return re.sub(clean, '', str(text))\n",
        "\n",
        "# Apply cleaning to the 'answerText' column\n",
        "df['clean_answer'] = df['answerText'].apply(remove_html_tags)\n",
        "\n",
        "# Optional: Combine questionTitle and questionText for better context\n",
        "df['full_question'] = df['questionTitle'].fillna('') + ' ' + df['questionText'].fillna('')\n",
        "\n",
        "# Preview the cleaned data\n",
        "df[['full_question', 'clean_answer']].head()\n",
        "# Display first few rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MRE8rtbVSwr"
      },
      "outputs": [],
      "source": [
        "# Display column names\n",
        "print(\"Column Names:\", df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIZ0N8dtVb1Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import html\n",
        "\n",
        "# Apply to the cleaned answer column\n",
        "df['decoded_answer'] = df['clean_answer'].apply(html.unescape)\n",
        "\n",
        "# Optional: also decode the question column if needed\n",
        "df['decoded_question'] = df['full_question'].apply(html.unescape)\n",
        "\n",
        "# Preview\n",
        "df[['decoded_question', 'decoded_answer']].head()"
      ],
      "metadata": {
        "id": "NScBlxHW6WRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant columns\n",
        "questions = df[\"decoded_question\"].dropna().tolist()  # Remove NaN values if any\n",
        "answers = df[\"decoded_answer\"].dropna().tolist()\n",
        "\n",
        "# Print a sample\n",
        "print(\"Sample Question:\", questions[0])\n",
        "print(\"Sample Answer:\", answers[0])"
      ],
      "metadata": {
        "id": "F0dQrTF46ehc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfcRTbiAWBH7"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR_mFmCdWCuZ"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# General Mental Health Support Prompt (already defined)\n",
        "general_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a compassionate therapist. Respond with empathy, support, and actionable advice.\n",
        "Maintain a warm and understanding tone. If necessary, suggest mindfulness, therapy, or self-care techniques.\n",
        "\n",
        "Client: {client_message}\n",
        "Therapist:\n",
        "\"\"\",\n",
        "    input_variables=[\"client_message\"],\n",
        ")\n",
        "\n",
        "# Anxiety-specific Prompt\n",
        "anxiety_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are an empathetic therapist specialized in anxiety management. Provide calm, supportive, and actionable advice specifically targeted towards managing anxiety. Suggest practical techniques like mindfulness, breathing exercises, or grounding practices.\n",
        "\n",
        "Client: {client_message}\n",
        "Therapist:\n",
        "\"\"\",\n",
        "    input_variables=[\"client_message\"],\n",
        ")\n",
        "\n",
        "# Depression-specific Prompt\n",
        "depression_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a compassionate therapist specialized in supporting clients experiencing sadness, depression, or feelings of hopelessness. Offer empathy, reassurance, and practical suggestions such as self-care activities, reaching out for support, or considering therapy.\n",
        "\n",
        "Client: {client_message}\n",
        "Therapist:\n",
        "\"\"\",\n",
        "    input_variables=[\"client_message\"],\n",
        ")\n",
        "\n",
        "# Relationship-specific Prompt\n",
        "relationship_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a caring therapist specializing in relationship and family counseling. Provide empathetic and practical advice on communication strategies, understanding perspectives, conflict resolution, or improving interpersonal relationships.\n",
        "\n",
        "Client: {client_message}\n",
        "Therapist:\n",
        "\"\"\",\n",
        "    input_variables=[\"client_message\"],\n",
        ")\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "client_message = \"I've been feeling very anxious lately and don't know how to cope.\"\n",
        "formatted_prompt = general_prompt.format(client_message=client_message)\n",
        "print(formatted_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO49G-vlWNte"
      },
      "outputs": [],
      "source": [
        "def get_prompt(client_message):\n",
        "    if any(word in client_message.lower() for word in [\"anxious\", \"panic\", \"overwhelmed\"]):\n",
        "        return anxiety_prompt.format(client_message=client_message)\n",
        "    elif any(word in client_message.lower() for word in [\"depressed\", \"hopeless\", \"sad\"]):\n",
        "        return depression_prompt.format(client_message=client_message)\n",
        "    elif any(word in client_message.lower() for word in [\"relationship\", \"partner\", \"marriage\", \"family\"]):\n",
        "        return relationship_prompt.format(client_message=client_message)\n",
        "    else:\n",
        "        return general_prompt.format(client_message=client_message)\n",
        "\n",
        "# Example Test\n",
        "test_message = \"I'm having serious conflicts with my wife, and I feel stuck.\"\n",
        "selected_prompt = get_prompt(test_message)\n",
        "print(selected_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KlCtOh8Wk6W"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YE3DCXhXZ_R"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55CDXWphYJ_a"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "try:\n",
        "    response = requests.get(\"https://huggingface.co\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        print(\" Internet is working. Hugging Face is reachable!\")\n",
        "    else:\n",
        "        print(\" Internet issue: Received status code\", response.status_code)\n",
        "except requests.ConnectionError:\n",
        "    print(\" No internet connection detected!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajR7TQDVWlvi"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "#  Load tokenizer\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "#  Fix: Set padding token to avoid ValueError when padding\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#  Load model with half precision and auto device mapping\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee6wplHJZjwk"
      },
      "outputs": [],
      "source": [
        "def generate_response(client_message):\n",
        "    # Format the structured prompt\n",
        "    prompt = f\"\"\"\n",
        "    You are a compassionate therapist. Respond with empathy, support, and actionable advice.\n",
        "    Maintain a warm and understanding tone. If necessary, suggest mindfulness, therapy, or self-care techniques.\n",
        "\n",
        "    Client: {client_message}\n",
        "    Therapist:\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=200, temperature=0.7, top_p=0.9)\n",
        "\n",
        "    # Decode and return the response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "#  Test the chatbot\n",
        "test_message = \"I've been feeling very anxious lately and don't know how to cope.\"\n",
        "response = generate_response(test_message)\n",
        "print(\"\\nChatbot Response:\\n\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txF0CuyjaJMJ"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate sacrebleu nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBmd8x73aVfQ"
      },
      "outputs": [],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQK9u-DPaN6O"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import math\n",
        "import torch\n",
        "import nltk\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "nltk.download(\"punkt\")  # Needed for tokenization in BLEU & ROUGE\n",
        "\n",
        "# Load BLEU and ROUGE metrics from Hugging Face's Evaluate library\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "# Function to calculate perplexity\n",
        "def calculate_perplexity(response):\n",
        "    inputs = tokenizer(response, return_tensors=\"pt\").to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "    loss = outputs.loss\n",
        "    perplexity = math.exp(loss.item())\n",
        "    return perplexity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IjwVHdBaRi_"
      },
      "outputs": [],
      "source": [
        "def evaluate_response(generated_response, reference_response):\n",
        "    # Compute BLEU score (expects full sentences, not tokenized words)\n",
        "    bleu_score = bleu.compute(predictions=[generated_response], references=[[reference_response]])\n",
        "\n",
        "    # Compute ROUGE score (expects full sentences)\n",
        "    rouge_score = rouge.compute(predictions=[generated_response], references=[reference_response])\n",
        "\n",
        "    # Compute perplexity\n",
        "    perplexity = calculate_perplexity(generated_response)\n",
        "\n",
        "    return {\n",
        "        \"BLEU Score\": bleu_score[\"bleu\"],\n",
        "        \"ROUGE Score\": rouge_score[\"rouge1\"],\n",
        "        \"Perplexity\": perplexity\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoY4Xgroaddb"
      },
      "outputs": [],
      "source": [
        " import nltk\n",
        " nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTgqoRKVaSNw"
      },
      "outputs": [],
      "source": [
        "# Example chatbot response vs reference therapist response\n",
        "generated_response = \"\"\"\n",
        "I'm sorry to hear that you're feeling anxious. It's completely normal to experience anxiety at times, but it's important to address it when it becomes overwhelming.\n",
        "One helpful technique to manage anxiety is mindfulness meditation. This involves focusing on the present moment and accepting your thoughts and feelings without judgment.\n",
        "\"\"\"\n",
        "reference_response = \"\"\"\n",
        "I hear that you're feeling anxious, and that's completely understandable. A helpful way to manage anxiety is practicing deep breathing exercises or grounding techniques.\n",
        "Taking a moment to focus on your breath or journaling can also be beneficial. Would you like to explore more coping strategies together?\n",
        "\"\"\"\n",
        "\n",
        "# Run evaluation\n",
        "scores = evaluate_response(generated_response, reference_response)\n",
        "print(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XobvG13bBDi"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmpGAqjUa2Er"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu langchain chromadb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZH1fMzqa22U"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Load a free embedding model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Free alternative to OpenAIEmbeddings\n",
        "\n",
        "# Example dataset\n",
        "conversation_texts = [\n",
        "    \"How do I deal with anxiety?\",\n",
        "    \"What should I do if I'm feeling very anxious?\",\n",
        "    \"How can I manage stress effectively?\",\n",
        "    \"I've been feeling overwhelmed at work, how do I handle it?\"\n",
        "]\n",
        "\n",
        "# Convert questions to vector embeddings\n",
        "vectors = embedding_model.encode(conversation_texts, convert_to_numpy=True)\n",
        "\n",
        "# Create FAISS index\n",
        "vector_array = np.array(vectors, dtype=np.float32)\n",
        "faiss_index = faiss.IndexFlatL2(vector_array.shape[1])\n",
        "faiss_index.add(vector_array)\n",
        "print(\"FAISS Index Created Successfully with SentenceTransformers!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR1IimklbVbV"
      },
      "outputs": [],
      "source": [
        "def retrieve_context(query, top_k=2):\n",
        "    query_vector = np.array([embedding_model.encode(query)], dtype=np.float32)\n",
        "    distances, indices = faiss_index.search(query_vector, k=top_k)\n",
        "\n",
        "    # Fetch similar questions and associated answers explicitly\n",
        "    similar_q_and_a = [\n",
        "        (conversation_texts[i], df['decoded_answer'].iloc[i])\n",
        "        for i in indices[0]\n",
        "    ]\n",
        "    return similar_q_and_a\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_response_with_rag(client_message):\n",
        "    # Retrieve similar past questions and answers\n",
        "    context_qas = retrieve_context(client_message)\n",
        "\n",
        "    # Format the retrieved context for clarity\n",
        "    formatted_context = \"\\n\\n\".join([f\"Q: {q}\\nA: {a}\" for q, a in context_qas])\n",
        "\n",
        "    #  Enhanced prompt with clear instructions\n",
        "    prompt = f\"\"\"\n",
        "You are a compassionate therapist helping people with mental health concerns.\n",
        "\n",
        "Below are similar past conversations that might help you understand the client's situation better and guide your response:\n",
        "\n",
        "{formatted_context}\n",
        "\n",
        "Based on the above context, now respond to the client below with empathy and actionable advice.\n",
        "Your response should be emotionally supportive and, if appropriate, recommend mindfulness, self-care, or therapeutic strategies.\n",
        "\n",
        "Client: {client_message}\n",
        "Therapist:\n",
        "\"\"\"\n",
        "\n",
        "    # Tokenize and generate\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.2,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode and return just the therapist's message\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = response.split(\"Therapist:\")[-1].strip()\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "MQCEyYLi8FMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_messages = [\n",
        "    \"hello i am sad\",\n",
        "    \"i feel overwhelmed by everything at work\",\n",
        "    \"my mom and wife keep arguing and itâ€™s stressing me out\",\n",
        "    \"i can't sleep at night and keep overthinking\"\n",
        "]\n",
        "\n",
        "for msg in test_messages:\n",
        "    print(\"\\nClient:\", msg)\n",
        "    print(\"Therapist:\", generate_response_with_rag(msg))\n",
        "    print(evaluate_response())"
      ],
      "metadata": {
        "id": "5x6hqhsA-5a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_response"
      ],
      "metadata": {
        "id": "W9I4XlXZ3YN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIAXW0-d3x-4"
      },
      "outputs": [],
      "source": [
        "# Example chatbot response vs reference therapist response\n",
        "generated_response = \"\"\"\n",
        "I'm sorry to hear that you're feeling anxious. It's completely normal to experience anxiety at times, but it's important to address it when it becomes overwhelming.\n",
        "One helpful technique to manage anxiety is mindfulness meditation. This involves focusing on the present moment and accepting your thoughts and feelings without judgment.\n",
        "\"\"\"\n",
        "reference_response = \"\"\"\n",
        "I hear that you're feeling anxious, and that's completely understandable. A helpful way to manage anxiety is practicing deep breathing exercises or grounding techniques.\n",
        "Taking a moment to focus on your breath or journaling can also be beneficial. Would you like to explore more coping strategies together?\n",
        "\"\"\"\n",
        "\n",
        "# Run evaluation\n",
        "scores = evaluate_response(generated_response, reference_response)\n",
        "print(scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backend Setup\n"
      ],
      "metadata": {
        "id": "TAvsaQ1nOVtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install flask flask-cors --quiet\n",
        "!pip install pyngrok --quiet\n",
        "!pip install transformers accelerate --quiet\n"
      ],
      "metadata": {
        "id": "KlV-UnkZOVdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "# Set your authtoken here (paste your token inside the quotes)\n",
        "ngrok.set_auth_token(\"NGROK_TOKEN\")\n"
      ],
      "metadata": {
        "id": "zNuGLyGKRIo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "from langchain.prompts import PromptTemplate\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "\n",
        "general_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a compassionate therapist. Respond with empathy, support, and actionable advice.\n",
        "Maintain a warm and understanding tone. If necessary, suggest mindfulness, therapy, or self-care techniques.\n",
        "\n",
        "Client: {client_message}\n",
        "Therapist:\"\"\",\n",
        "    input_variables=[\"client_message\"],\n",
        ")\n",
        "\n",
        "anxiety_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a calm and reassuring mental health assistant. The user is feeling anxious or overwhelmed.\n",
        "Offer calming techniques, grounding exercises, and positive affirmations.\n",
        "\n",
        "Client: {client_message}\n",
        "Therapist:\"\"\",\n",
        "    input_variables=[\"client_message\"],\n",
        ")\n",
        "\n",
        "depression_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a caring and understanding therapist. The user feels depressed, hopeless, or sad.\n",
        "Listen supportively and offer encouragement, self-compassion practices, and gentle help.\n",
        "\n",
        "Client: {client_message}\n",
        "Therapist:\"\"\",\n",
        "    input_variables=[\"client_message\"],\n",
        ")\n",
        "\n",
        "relationship_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are a relationship counselor. The user is experiencing issues in relationships or family.\n",
        "Help them understand their emotions and suggest communication strategies.\n",
        "\n",
        "Client: {client_message}\n",
        "Therapist:\"\"\",\n",
        "    input_variables=[\"client_message\"],\n",
        ")\n",
        "\n",
        "def get_prompt(client_message):\n",
        "    message = client_message.lower()\n",
        "    if any(word in message for word in [\"anxious\", \"panic\", \"overwhelmed\"]):\n",
        "        return anxiety_prompt.format(client_message=client_message)\n",
        "    elif any(word in message for word in [\"depressed\", \"hopeless\", \"sad\"]):\n",
        "        return depression_prompt.format(client_message=client_message)\n",
        "    elif any(word in message for word in [\"relationship\", \"partner\", \"marriage\", \"family\"]):\n",
        "        return relationship_prompt.format(client_message=client_message)\n",
        "    else:\n",
        "        return general_prompt.format(client_message=client_message)\n",
        "\n",
        "def run_model(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=150)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route(\"/chat\", methods=[\"POST\"])\n",
        "def chat():\n",
        "    data = request.json\n",
        "    user_input = data.get(\"message\", \"\")\n",
        "    prompt = get_prompt(user_input)\n",
        "    response = run_model(prompt)\n",
        "    return jsonify({\"response\": response})\n",
        "\n",
        "port = 5001\n",
        "public_url = ngrok.connect(port)\n",
        "print(f\"ðŸš€ Public URL: {public_url}\")\n",
        "app.run(port=port)\n"
      ],
      "metadata": {
        "id": "yGng2s3HRf3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}